\documentclass[landscape]{foils}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{hyperref}
\input defs.tex
\raggedright
\special{! TeXDict begin /landplus90{true}store end }
\renewcommand{\oursection}[1]{
\foilhead[-1.0cm]{#1}
}
\newcommand{\myfig}[1]{
    \begin{figure}[!h]
    \centerline{\includegraphics[height=6.5cm]{fig/#1.jpg}}
    \end{figure}
}
\newcommand{\BI}{\begin{itemize}\item}
\newcommand{\I}{\item}
\newcommand{\EI}{\end{itemize}}

\title{Nanophotonic Computational Design}
\author{Jesse Lu}
\MyLogo{Jesse Lu, Jelena Vuckovic group, Stanford University}
\date{February 25, 2013}

\begin{document}
\setlength{\parskip}{0cm}
\maketitle

% \BIT \itemsep -1pt
% \item motivation
% \item theory
% \item results
% \EIT

\vfill
\newpage

Takeaway: Taught a computer to design nanophotonic devices
\myfig{placeholder}
\vfill
\newpage

\oursection{Part 1: Motivation}
\myfig{optical_networks}
\BI As information grows, optical networks needed
    \BI across continents
    \I  within a datacenter
    \I  between chips and on-chip \EI
\newpage

\I  An on-chip optical network is a fundamentally new optical communications
    technology: \emph{the integrated optical circuit}
\myfig{integrated_circuit}
\I  Miniaturization drives
    \BI component price down
    \I  functionality up
    \I  design complexity (way) up \EI
\newpage

\I  Increasing design complexity requires additional degrees of freedom
\I  Fortunately, we have a virtually unlimited amount
\myfig{des_complexity}
\I  Include/exclude per pixel gives us $2^{(15^2)} = 2^{225}$ possibilities, 
    uncountable
\vfill
\newpage

\I  Only feasible solution: Humans describe, Computers design

\begin{verbatim}
device mux2 
    in: {freq1, freq2}
    out1 <= freq1
    out2 <= freq2
\end{verbatim}
\EI
\myfig{placeholder}

\oursection{Part 2: Theory}

\BI First, cast electromagnetic wave equation into linear algebra terms
\BE (\nabla\times\mu^{-1}_0\nabla\times - \omega^2\epsilon)E + i\omega J = 0
    \longrightarrow A(z)x - b = 0
\EE
where
\begin{align*}
    E &\to x \\
    \epsilon &\to z \\
    \nabla\times\mu^{-1}_0\nabla\times - \omega^2\epsilon &\to A(z) \\
    -i\omega J &\to b
\end{align*}
\I  $A(z)x - b$ is called the \emph{physics residual}
\vfill
\newpage

\I  Secondly, formulate our optimization objective
\BE f(x) = (\alpha - |c\T x|)^2 \EE
\I  $c\T x$ is equivalent to overlap integral $\int E_t^* E$
\I  To design linear devices, objective chosen to be 
    overlap integral with target field at output port
\I  $f(x)$ is called the \emph{field design objective}
\vfill
\newpage

\I  Typically,
\begin{align*}
    \minimize & (\alpha - |c\T x|)^2 \\
    \subto & A(z)x - b = 0
\end{align*}
% \I  Proceed by updating $z$ via steepest-descent,
% \BE z_\text{next} = z_\text{curr} - \kappa \frac{df(x)}{dz} \EE
\myfig{placeholder}
\I  Efficient algorithm known as the \emph{adjoint method}
\newpage

\I  Our alternative formulation, known as \emph{objective-first}
\begin{align*}
    \minimize & \|A(z)x - b\|^2 \\
    \subto & |c\T x| = \alpha 
\end{align*}
\myfig{placeholder}
\I  Perfect performance always enforced, 
    even at the expense of breaking physical laws
\newpage

\I  Results in \emph{soft-physics} solves
\myfig{placeholder}
\I  Key insight: soft-physics solution suggests optimal structure
\newpage

\begin{align*}
    \minimize & \|A(z)x - b\|^2 \\
    \subto & |c\T x| = \alpha 
\end{align*}
\I  Could be solved by iteratively solving for $x$ and $z$
    \BI Known as \emph{alternating directions}
    \I  Takes advantage of bi-linearity of the physics residual,
    \BE A(z)x - b = B(x)z - d(x) \EE \EI
\I  \emph{Alternating directions method of multipliers (ADMM)}
    gives much faster convergence
    \BI Due to introduction of dual variable \EI
\vfill
\newpage

\I  Full problem is multi-mode and multi-output
\I  Objective-first formulation:
\begin{align*}
    \minimize & \sum_i^M \|A_i(z)x_i - b_i\|^2 \\
    \subto & \alpha_{ij} \le |c_{ij}\T x_i| \le \beta_{ij}, \quad
        \text{for $i = 1, \ldots, M$ and $j = 1, \ldots, N_i$}
\end{align*}
\I  Adjoint method formulation:
\begin{align*}
    \minimize & \sum_{ij}^{M,N_i} \max\{\alpha_{ij}-|c_{ij}\T x_i|, 
                                        |c_{ij}\T x_i|-\beta_{ij}, 0\} \\
    \subto & A_i(z) x_i - b_i = 0, \quad
        \text{for $i = 1, \ldots, M$}
\end{align*}
\newpage

\oursection{Part 3: Method}

\oursection{Part 4: Results}

    
\EI 

    
%     
% \EI
% Problem formulation:
%     \begin{subequations}\begin{align}
%     \mbox{optimize} \quad & f_\text{perf}(H) + 
%                             g_\text{manuf}(\epsilon) \\
%     \subjectto & \nabla \times \epsilon^{-1} \nabla \times H -
%                         \mu \omega^2 H = 0
%     \end{align}\end{subequations}
% 
% In the language of linear algebra,
%     \begin{subequations}\begin{align}
%     \minimize & f(x) + g(p) \\
%     \subjectto & r(x, p) = 0
%     \end{align}\end{subequations}
% \BIT
% \item $x$ is the field variable , $p$ is the {structure} variable
% \item $f(x) + g(p)$ is the {design objective}
% \item $r(x,p)$ is the {physics residual}
% \EIT
% \newpage
%     
% \oursection{Generic nonlinear optimization packages}
% \BIT
% \item It is possible to efficiently compute the following:
%     \BIT
%     \item Zeroth-order: $f$, $g$, $r$, and $\|r\|^2$ 
%     \item First-order: $\nabla f$, $\nabla g$, $\nabla r$, and $\nabla \|r\|^2$ 
%     \item Second-order: $\nabla^2 f$, $\nabla^2 g$, and $\nabla^2 \|r\|^2$ 
%     \EIT
% 
% \item However, most efficient solvers require computing 
%         either $(\nabla r)^{-1}z$ or $(\nabla^2 \|r\|^2)^{-1})z$,
%         which is often very difficult!
% 
% \item Many viable approximations exist, 
%     but convergence is often slow and unreliable.
% \EIT
% 
% % \begin{center} \emph{My choice: Stick with what works.} \end{center}
% \newpage
% 
% \oursection{Key insights/assumptions}
% \begin{enumerate}
% \item $r(x,p)$ is separably affine (bi-affine) in $x$ and $p$,
%     \begin{equation}
%     r(x,p) = A(p)x - b(p) = B(x) p - d(x),
%     \end{equation}
%         this allows us to form two simpler sub-problems.
% 
% \item Simulators which compute $A(p)^{-1} z$ are available, 
%         even for very large systems (millions of variables).
% 
% \item Solving $B(x) p - d(x) = 0$ is possible, 
%         because manufacturing processes severely limit
%         the degrees of freedom of $p$ 
%         (decreases $p$ to thousands of variables).
% \end{enumerate}
% 
% \oursection{Adjoint method}
% \BIT
% \item Starting at $r(x_0, p_0) = 0$, solves 
%     \begin{subequations}\begin{align}
%     \minimize & f(x) + g(p) \\
%     \subjectto & r(x, p) = 0
%     \end{align}\end{subequations}
%     by steepest descent along $\frac{df}{dp} + \frac{dg}{dp}$
%     while enforcing $r(x,p) = 0$.
% 
% \item Computationally efficient because $\frac{df}{dp}$ is computed
%         in a single simulation.
% 
% \item A total of only two simulations required per iteration.
% 
% \item Steepest-descent methods usually exhibit very slow convergence,
%         but this method has proven very useful in practice,
%         especially because $r(x,p) = 0$ at every iteration.
% \EIT
% 
% \oursection{Alternating directions}
% \BIT
% \item Alternatively, we can break our problem into two separate subproblems,
%         taking advantage of 
%         \begin{equation} 
%             r(x,p) = A(p)x - b(p) = B(x) p - d(x).
%         \end{equation}
% 
% \item $x$ and $p$ are iteratively updated,
%     \begin{subequations}\begin{align}
%         x &:= \argmin_x f(x) + \frac{\rho}{2} \| Ax - b \|^2 \\
%         p &:= \argmin_p g(p) + \frac{\rho}{2} \| Bp - d \|^2.
%     \end{align}\end{subequations}
% 
% \item Allows us to start from $r(x_0, p_0) \neq 0$ and then
%         gradually increase $\rho$ until $r(x,p) = 0$.
% \EIT
% 
% \oursection{Alternating directions method of multipliers (ADMM)}
% \BIT
% \item Include additional (dual) variable $y$,
%     \begin{subequations}\begin{align}
%         x &:= \argmin_x f(x) + \frac{\rho}{2} \| Ax - b \|^2  + y^T (Ax - b)\\
%         p &:= \argmin_p g(p) + \frac{\rho}{2} \| Bp - d \|^2 + y^T (Bp - d) \\
%         y &:= y + \rho r(x,p)
%     \end{align}\end{subequations}
% 
% \item Works for fixed $\rho$ and generally exhibits faster convergence 
%         than alternating directions.
% 
% \item We assume that updating $x$ takes up the most computational resources.
% \EIT
% \newpage
% 
% \BIT
% \item For what choices of $f(x)$ can we efficiently solve
%         \begin{multline}
%         \argmin_x L(x,p,y) = 
%             \argmin_x f(x) + \frac{\rho}{2} \| Ax - b \|^2  + y^T (Ax - b)
%         \end{multline}
% 
% \item Solve quadratic approximation (Newton's method),
%     \begin{equation}
%     \Delta x = (\nabla^2_{xx} L)^{-1} \nabla_x L,
%     \end{equation}
%     where
%     \begin{subequations}\begin{align}
%     \nabla_x L(x,p,y) &= \nabla f(x) + A^T (\rho (Ax - b) + y) \\
%     \nabla^2_{xx} L(x,p,y) &= \nabla^2 f(x) + \rho A^T A
%     \end{align}\end{subequations}
% 
% \item Assumption: for general $\nabla^2 f(x)$, $\nabla^2_{xx} L(x,p,y)$ 
%     \emph{cannot} be inverted.
% \EIT
% \newpage
% 
% \BIT
% \item Case 1: $f(x) = c^T x$, Field overlap integral
% \item In this case 
%     \begin{subequations}\begin{align}
%     (\nabla^2_{xx} L(x,p,y))^{-1} &= 
%         \rho^{-1} (A^T A)^{-1} = \rho^{-1} A^{-1} A^{-T} \\
%     \nabla_x L(x,p,y) &= c + A^T (\rho (Ax - b) + y),
%     \end{align}\end{subequations}
%     so we can solve 
%     \begin{subequations}\begin{align}
%     \Delta x &= (\nabla^2_{xx} L)^{-1} \nabla_x L \\
%         &= \rho^{-1} A^{-1}( A^{-T} c + \rho(Ax - b) + y)
%     \end{align}\end{subequations}
%     using only two simulations.
% \item Since $L(x,p,y)$ is exactly quadratic, 
%         we can update $x$ using only two simulations.
% \EIT
% \newpage
% 
% \BIT
% \item Case 2: $f(x) = \|C^T x\|^2$, Energy in mode
% \item Case 3: $f(x)$ forces $C^T x = d$.
% \item Also, multi-mode.
% % \item Use matrix inversion lemma,
% %     \begin{subequations}\begin{align}
% %     (\nabla^2_{xx} L(x,p,y))^{-1} &= 
% %         (CC^T + \rho(A^T A))^{-1} \\
% %         &= (\rho A^T A)^-1 + ( \\
% %     \nabla_x L(x,p,y) &= c + A^T (\rho (Ax - b) + y),
% %     \end{align}\end{subequations}
% %     so we can solve 
% %     \begin{subequations}\begin{align}
% %     \Delta x &= (\nabla^2_{xx} L)^{-1} \nabla_x L \\
% %         &= \rho^{-1} A^{-1}( A^{-T} c + \rho(Ax - b) + y)
% %     \end{align}\end{subequations}
% %     using only two simulations.
% % \item Since $L(x,p,y)$ is exactly quadratic, 
% %         we can update $x$ using only two simulations.
% \EIT
% 
% % \oursection{Plan}
% % \BIT
% % \item Software to solve $A^{-1}z$.
% % \item Adjoint
% % \EIT
\end{document}
