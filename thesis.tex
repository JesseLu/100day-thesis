% Compile with:
% latex --halt-on-error thesis.tex && latex thesis.tex && dvips thesis.dvi && ps2pdf thesis.ps

\documentclass{article}
\usepackage{pstricks}
\usepackage{amsmath}
\newcommand{\E}[2]{\begin{align}#2\label{eq:#1}\end{align}}
\newcommand{\EE}[2]{\begin{subequations}\begin{align}#2\end{align}\label{eq:#1}\end{subequations}}
\newcommand{\curl}{\nabla\times}
\newcommand{\eq}[1]{\eqref{eq:#1}}
\newcommand{\fig}[1]{figure~\ref{fig:#1}}
\newcommand{\MaxwellFDS}{MaxwellFDS }
\newcommand{\BI}{\begin{itemize}\item}
\newcommand{\EI}{\end{itemize}}
\newcommand{\I}{\item}
\newcommand{\pf}[1]{\frac{\partial}{\partial #1}} % d/d_
\newcommand{\prim}{\text{prim}}
\newcommand{\dual}{\text{dual}}
\newcommand{\mx}{\text{max}}
\newcommand{\diag}{\text{diag}}
\title{Harnessing the cloud to understand light: 
        A whitepaper detailing the \MaxwellFDS core solver}
\begin{document}
\maketitle
\tableofcontents

\section*{Introduction}
\MaxwellFDS is a cloud-powered electromagnetic solver,
    tailored specifically to the field of nanophotonics.
\MaxwellFDS stands for Frequency-Domain Solver.

\section{Motivation: why another electromagnetic solver?}
Although many electromagnetic simulation packages are currently available,
    we found it necessary, for our own purposes, to create our own.
Specifically, we desired a simulator which 
    \BI operates in the frequency-domain, as opposed to the time-domain.
    \I  scales to multiple high-resolution three-dimensional domains,
    \I  is readily accessible via Matlab. \EI

\subsection{The advantages of frequency-domain solutions}
The advantages of solving Maxwell's equations in the  \emph{frequency}-domain 
    as opposed to simulating them in the \emph{time}-domain include
    \BI clean excitation of input modes,
    \I  precise characterization of material dispersion,
    \I  calculation of figure of merits outside of the simulation,
    \I  explicit measurement of simulation error, and
    \I  explicit calculation of eigenmodes. \EI

\subsubsection{Input: clean excitation of modes}
A clean input excitation is typically quite complex to set up
    in a time-domain simulation,
    often requiring an auxiliary simulation to be run in parallel.
The finite bandwidth of the excitation makes the calculation
    of the mode profile problematic, while
    the need to suppress transients requires the use of 
    long ``build-up'' excitations.
These difficulties are illustrated in \fig{time domain diagram}
    where the inputs at the various frequencies of interest
    must be combined and converted into the time-domain.

However, in a frequency-domain simulation, 
    since $\omega$ is explicitly defined and has no bandwidth,
    one can accurately compute the correct input mode.
Additionally, since one does not need to deal with transient excitations,
    the input mode can be inserted directly into the simulation
    without skilled ``tweaking'' on the part of the user,
    as illustrated in \fig{frequency domain diagram}
    where each frequency of interest is given it's own simulation.
 
\begin{figure}[ht]\begin{center}
\input{tds-fig.tex}
\caption{The difficulties of working in the time-domain.
        On the input side, the various input modes must be
            combined and converted to the time-domain.
        At the same time, the output measures of performance 
            must be extracted from the time-domain output
            while the simulation is still running.}
\label{fig:time domain diagram}
\end{center} \end{figure}

\begin{figure}[ht]\begin{center}
\input{fds-fig.tex}
\caption{Using a frequency domain solver,
            the various input modes and output measures
            are computed independently of one another,
            greatly simplifying the user's workflow.}
\label{fig:frequency domain diagram}
\end{center} \end{figure}

\subsubsection{Dispersion: precise characterization of frequency-dispersion}
In a similar vein, the explicitness of $\omega$ means that
    parameters which depend upon frequency can be accurately simulated
    by simply supplying the correct value of the parameter at the 
    chosen frequency.

This is in contrast to time-domain solutions,
    which rely on running integrals to approximate such behavior.
    
\subsubsection{Output: complete description of device performance}
An additional advantage to frequency-domain solutions
    is that all the information concerning the solution
    is contained in the output field.
This means that the calculation of figures of merit and 
    any possible measure of performance happens only
    after the solver has completed, 
    as shown in \fig{frequency domain diagram}.

This is in contrast to time-domain simulations,
    where such calculations must occur as the simulation proceeds, 
    as shown in \fig{time domain diagram},
    since the entire field at every point in time cannot be stored in memory.

\subsubsection{Error: explicit measurement of simulation error}
Yet another advantage of frequency-domain solutions is the ability
    to explicitly calculate the error in the solution fields,
    which is impossible to do with time-domain simulations.

\subsubsection{Eigenmodes: explicit calculation of eigenmodes}
Explicitly calculating the error also allows one 
    to explicitly calculate eigenmode solutions
    using frequency-domain solvers.
This is particularly useful when one is attempting to
    discriminate between closely spaced modes,
    which is very difficult using time-domain approaches.

\subsection{The advantages of simulating in the cloud}
The primary usefulness of the cloud in a simulation context
    is that it allows one to save both money and time.

\subsubsection{Cloud computing allows for ``free'' parallelism}
The most fundamental difference in running simulations
    in a cloud computing environment is its cost structure.
Specifically, in the cloud, 
    one is billed based on the amount of computational resources used
    and the time which one uses those resources.
In contrast, the cost of simulating on one's own hardware
    depends most heavily on the amount of hardware needed,
    at least in most scientific environments.

The disruptive cost structure of cloud environments 
    has profound effects on scientific workloads 
    as illustrated in \fig{cloud vs traditional};
    in essence, allowing scientific workloads access
    to ``free'' parallelism.
The parallelism is free in the sense that 
    the cost of running $N$ jobs sequentially on $1$ computer is equivalent to 
    the cost of running $N$ jobs in parallel on $N$ computers.

\begin{figure}[ht]\begin{center}
\input{cloud-fig.tex}
\caption{The fundamental difference in going to the cloud
            is that both sequential and parallel workloads
            cost the same amount of money,
            since one is billed based on time $\times$ resources.
        In contrast, simulating on one's own hardware would 
            mean that parallel workloads are much more expensive
            since one is billed on resources alone.
        In essence, therefore, cloud computing allows for 
            parallelism at no cost.}
\label{fig:cloud vs traditional}
\end{center} \end{figure}

\subsubsection{Cloud computing takes care of all messy hardware details}
A secondary benefit in using cloud computing 
    is that many details no longer need to be handled such as
    \BI physically installing, maintaining, and fixing computational hardware,
    \I  ensuring identical software configurations on every cluster node, and 
    \I  installing and configuring the cluster networking. \EI

Of course, these conveniences come at the expense of 
    being able to customize hardware, and networking resources
    to ideally suit an application's needs.
However, considering that most scientific folk
    are not experts in these issues,
    this can be considered a very small disadvantage.

\subsection{The advantages of being built within Matlab}
\MaxwellFDS was designed to not only be scalable (in the cloud),
    but accessible as well.
For this reason, we have allowed
    

\section{Harnessing Amazon's Elastic Compute Cloud} 
\subsection{Accessing }

\section{Solving the electromagnetic wave equation using \MaxwellFDS}
\subsection{Analytic derivation of the electromagnetic wave equation}
The electromagnetic wave equation can be derived from 
    the differential form of Maxwell's equations, that is,
\EE {maxwell diff}
    {\curl E &= - \mu \frac{\partial H}{\partial t} \\
    \curl H &= J + \epsilon \frac{\partial E}{\partial t}, }
    where $E$, $H$, and $J$ are 
    the electric, magnetic and electric current
    vector fields, respectively,
    $\epsilon$ is the permittivity
    and $\mu$ is the permeability.

Assuming the time dependence $\exp(-i \omega t)$, 
    where $\omega$ is the angular frequency,
    these become
\EE {maxwell harmonic}
    {\curl E &= - i \mu \omega H \\
    \curl H &= J + i \epsilon \omega E,}
    which we can combine to form the time-harmonic wave equation for $E$,
    \E{maxwell wave E}
    {\curl \mu^{-1} \curl E - \epsilon \omega^2 E = -i \omega J,}
    which \MaxwellFDS solves

Note that the alternative wave equation for $H$,
    where we consider the magnetic current source $M$
    instead of $J$,
\E  {maxwell wave H}
    {\curl \epsilon^{-1} \curl H - \mu \omega^2 H = -i \omega M,}
    can also be solved using \MaxwellFDS.

\subsection{Numerical discretization of the wave equation}
\subsubsection{Use of the Yee cell}
To solve \eq{maxwell wave E} we discretize our vector fields 
    based on a primitive Yee cell, as shown in \fig{yee cell}. % Ref.
Similarly to the finite-difference time-domain simulation technique,
    the use of the Yee cell allows the $\curl$ operators to be well-defined.

\begin{figure}[ht]\begin{center}
    \input{yee-fig.tex}
    \end{center}
    \caption{   The primitive Yee cell. 
                The computational grid is formed by tiling this pattern
                    in three dimensions such that no two field components
                    of $E$ or $H$ are co-located. % Ref to Yee.
                The grid used in \MaxwellFDS has periodic ``wrap-around''
                    boundary conditions, and 
                    the relevant distances between adjacent field components
                    are denoted by $d^\prim_{x,y,z}$ and 
                    $d^\dual_{x,y,z}$.}
    \label{fig:yee cell}
\end{figure}

In this configuration, the $E$, $J$, and $\epsilon$ vector fields
    are positioned on the $E_{x,y,z}$ locations 
    while the $H$, $M$ (in the case of \eq{maxwell wave H}) , and $\mu$
    vector fields are placed on the $H_{x,y,z}$ locations.

To define the distances between adjacent field components,
    \MaxwellFDS uses the following convention:
    \BI $d^\prim_{w}$ denotes the distance in the direction $i$
        between $E_w$ components for $w = x, y, z$, and
    \I  $d^\dual_{w}$ denotes the distance in the direction $i$
        between $H_w$ components for $w = x, y, z$. \EI
This definition allows us to precisely define the numerical derivatives
    found in the $\curl$ operators.
    
\subsubsection{Use of a periodic ``wrap-around'' grid}
\MaxwellFDS features periodic ``wrap-around'' boundary conditions
    in the definition of the $\curl$ operators in \eq{maxwell wave E}.
For example, this means that the operation $\pf{x}H_y$ is still well-defined
    at the $x=0$ boundary as 
    $(H_y|^{x=0} - H_y|^{x = x_\mx}) / d^\prim_x$.

More specifically, \MaxwellFDS calls the elements 
    in the Yee cell at $(i,j,k)$ as $E_x(i,j,k)$, $E_y(i,j,k)$, \ldots 
    and then denotes 
\BI $d^\prim_x(0)$ as the distance 
    between $E_x(x_\mx,j,k)$ and $E_x(0,j,k)$,
\I  $d^\prim_y(0)$ as the distance 
    between $E_y(i,y_\mx,k)$ and $E_y(i,0,k)$,
\I  $d^\prim_z(0)$ as the distance 
    between $E_z(i,j,z_\mx)$ and $E_y(i,j,0)$,
\I  $d^\dual_x(x_\mx)$ as the distance 
    between $H_x(x_\mx,j,k)$ and $H_x(0,j,k)$,
\I  $d^\dual_y(y_\mx)$ as the distance 
    between $H_y(i,y_\mx,k)$ and $H_y(i,0,k)$, and
\I  $d^\dual_z(z_\mx)$ as the distance 
    between $H_z(i,j,z_\mx)$ and $H_y(i,j,0)$. \EI

It should be noted that \MaxwellFDS's strictly periodic grid still
    allows the use of Bloch periodic, mirror and perfectly-matched layer
    boundary conditions.
This is accomplished by setting the $d^{\prim,\dual}$ values to 
    the appropriate complex values or even $\infty$,
    both of which \MaxwellFDS is able to understand.
    
\subsubsection{The wave equation in terms of matrices and vectors}
With these definitions we now can see how \MaxwellFDS
    formulates the wave equation in the language of linear algebra.
Specifically, \MaxwellFDS formulates \eq{maxwell wave E} as
\E  {maxwell wave E discretized}
    {(A_1 \diag(\mu^{-1}) A_2 - \omega^2 \diag(\epsilon)) x = b,}
    where
    \BI $A_1$ and $A_2$ represent the first and second $\curl$ operators
        respectively,
    \I  $x \to E$, and
    \I  $b \to -i \omega J$. \EI

The vector fields $E$ is converted into vector $x$ as
\E{}{x = \begin{bmatrix} e_x \\ e_y \\ e_z \end{bmatrix}}
    where
\E{}{e_w = \begin{bmatrix} E_w(0,0,0) \\ E_w(1,0,0) \\
                        \vdots \\ E_w(x_\mx, y_\mx, z_\mx) \end{bmatrix},}
and so on for all vector fields.


\end{document}
